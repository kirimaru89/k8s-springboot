spring.application.name=com-vietinbank-kconsumer

# --START API INFO
api.info.title=Kafka Consumer API
api.info.version=1.0.0
api.info.description=Kafka Consumer API
# --END API INFO

# --START PROMETHEUS
# Expose Prometheus endpoint
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
# show all config properties, development only
management.endpoint.configprops.show-values=always 

# Enable all metrics
management.metrics.enable.all=true

# Enable JVM metrics
management.metrics.enable.jvm=true
# --END PROMETHEUS

# --START OPENTELEMETRY
# https://opentelemetry.io/docs/languages/java/configuration/
# https://opentelemetry.io/docs/zero-code/java/spring-boot-starter/out-of-the-box-instrumentation/

# send to otel collector via grpc, port 4317
otel.exporter.otlp.endpoint=http://my-opentelemetry-collector.monitoring.svc.cluster.local:4317
otel.exporter.otlp.protocol=grpc

otel.traces.sampler=parentbased_traceidratio
# development: 1.0, production: 0.1
otel.traces.sampler.arg=1.0

# --END OPENTELEMETRY

logging.level.org.apache.kafka.clients.producer.internals.Sender=DEBUG

# --START DATABASE
spring.datasource.url=jdbc:postgresql://my-postgresql-1:5432/k8spostgres
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.username=postgres
spring.datasource.password=Q9mn6pUr0i
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
# --END DATABASE

# --START KAFKA
# kafka config: https://gist.github.com/geunho/77f3f9a112ea327457353aa407328771
# kafka broker address
spring.kafka.bootstrap-servers=my-kafka-broker.monitoring.svc.cluster.local:9092

# # Make Kafka failure non-fatal for application startup
spring.kafka.producer.retry-backoff-ms=1000

# Consumer configuration
spring.kafka.consumer.group-id=${spring.application.name}-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.properties.isolation.level=read_committed
spring.kafka.consumer.properties.max.poll.interval.ms=300000
spring.kafka.consumer.properties.max.poll.records=10

# Enable debug logging for Kafka consumer
# logging.level.org.apache.kafka.clients.consumer=DEBUG
# logging.level.org.springframework.kafka=DEBUG
# --END KAFKA   

# --START RABBITMQ
spring.rabbitmq.host=my-rabbitmq.default.svc.cluster.local
spring.rabbitmq.port=5672
spring.rabbitmq.username=user
spring.rabbitmq.password=B23mrg9oZL5M7DKC
# --END RABBITMQ

# --START CACHE REDIS standalone
# redis config: https://docs.spring.io/spring-data/redis/docs/current/reference/html/#reference
spring.data.redis.host=host.docker.internal
spring.data.redis.port=6379
spring.data.redis.username=
spring.data.redis.password=

# Cache-specific TTL configurations
spring.cache.redis.cache-null-values=false
spring.cache.redis.key-prefix=${spring.application.name}
# --END CACHE REDIS standalone

# --START CACHE REDIS cluster
# spring.data.redis.cluster.nodes=redis-node-1:6379,redis-node-2:6379,redis-node-3:6379
# spring.data.redis.cluster.max-redirects=3
# spring.data.redis.cluster.password=your_password

# spring.cache.redis.cache-null-values=false
# spring.cache.redis.key-prefix=${spring.application.name}
# --END CACHE REDIS cluster