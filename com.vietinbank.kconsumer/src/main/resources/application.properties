spring.application.name=com-vietinbank-kconsumer

# --START API INFO
api.info.title=Kafka Consumer API
api.info.version=1.0.0
api.info.description=Kafka Consumer API
# --END API INFO

# --START PROMETHEUS
# Expose Prometheus endpoint
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
# show all config properties, development only
management.endpoint.configprops.show-values=always 

# Enable all metrics
management.metrics.enable.all=true

# Enable JVM metrics
management.metrics.enable.jvm=true
# --END PROMETHEUS

# --START OPENTELEMETRY
# https://opentelemetry.io/docs/languages/java/configuration/
# https://opentelemetry.io/docs/zero-code/java/spring-boot-starter/out-of-the-box-instrumentation/

# send to otel collector via grpc, port 4317
otel.exporter.otlp.endpoint=http://my-opentelemetry-collector.monitoring.svc.cluster.local:4317
otel.exporter.otlp.protocol=grpc

otel.traces.sampler=parentbased_traceidratio
# development: 1.0, production: 0.1
otel.traces.sampler.arg=1.0

# --END OPENTELEMETRY

logging.level.org.apache.kafka.clients.producer.internals.Sender=DEBUG

# --START DATABASE
spring.datasource.url=jdbc:postgresql://my-postgresql-1:5432/k8spostgres
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.username=postgres
spring.datasource.password=Q9mn6pUr0i
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true
# --END DATABASE

# --START KAFKA
# kafka config: https://gist.github.com/geunho/77f3f9a112ea327457353aa407328771
# kafka broker address
spring.kafka.bootstrap-servers=my-kafka-broker.monitoring.svc.cluster.local:9092

# producer key serializer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# producer value serializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# Enable idempotence to prevent duplicate messages during retries
spring.kafka.producer.properties.enable.idempotence=true
# acks: Required for idempotence
spring.kafka.producer.acks=all
# retries
spring.kafka.producer.retries=3
# transaction id prefix - if enable, we must send kafka message with in transaction
# spring.kafka.producer.transaction-id-prefix=tx-

# # Make Kafka failure non-fatal for application startup
# spring.kafka.consumer.properties.allow.auto.create.topics=true
spring.kafka.producer.retry-backoff-ms=1000
# --END KAFKA   

# --START CACHE
# redis config: https://docs.spring.io/spring-data/redis/docs/current/reference/html/#reference
spring.data.redis.host=host.docker.internal
spring.data.redis.port=6379
spring.data.redis.username=
spring.data.redis.password=

# cache config
cache.redis.key-prefix=${spring.application.name}
cache.redis.time-to-live=3600000
cache.redis.ttl.books=300000           # TTL for 'books' cache = 5 minutes
cache.redis.ttl.users=3600000         # TTL for 'users' cache = 1 hour
# --END CACHE