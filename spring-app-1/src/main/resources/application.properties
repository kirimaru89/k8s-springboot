# --START PROMETHEUS
# Expose Prometheus endpoint
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
# show all config properties, development only
management.endpoint.configprops.show-values=always 

# Enable all metrics
management.metrics.enable.all=true

# Enable JVM metrics
management.metrics.enable.jvm=true
# --END PROMETHEUS


spring.application.name=spring-app-1

# --START OPENTELEMETRY
# https://opentelemetry.io/docs/languages/java/configuration/
# https://opentelemetry.io/docs/zero-code/java/spring-boot-starter/out-of-the-box-instrumentation/

# send to otel collector via grpc, port 4317
otel.exporter.otlp.endpoint=http://my-opentelemetry-collector.monitoring.svc.cluster.local:4317
otel.exporter.otlp.protocol=grpc

otel.traces.sampler=parentbased_traceidratio
# development: 1.0, production: 0.1
otel.traces.sampler.arg=1.0

spring.kafka.bootstrap-servers=my-kafka-broker.monitoring.svc.cluster.local:9092

# Existing Kafka Producer Configuration
spring.kafka.producer.bootstrap-servers=my-kafka-broker.monitoring.svc.cluster.local:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# Add producer retry configuration
spring.kafka.producer.properties.retries=3
spring.kafka.producer.properties.retry.backoff.ms=1000
spring.kafka.producer.properties.delivery.timeout.ms=120000
spring.kafka.producer.properties.request.timeout.ms=30000

# Existing Kafka Consumer Configuration
spring.kafka.consumer.bootstrap-servers=my-kafka-broker.monitoring.svc.cluster.local:9092
spring.kafka.consumer.group-id=${spring.application.name}-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# Add consumer error handling properties
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.properties.max.poll.interval.ms=300000
spring.kafka.consumer.properties.max.poll.records=10
spring.kafka.listener.ack-mode=manual_immediate

# Kafka resilience configuration
spring.kafka.listener.missing-topics-fatal=false
spring.kafka.listener.ack-mode=MANUAL_IMMEDIATE
kafka.listener.missing-topics-fatal=false

# Make Kafka failure non-fatal for application startup
spring.kafka.consumer.properties.allow.auto.create.topics=true
spring.kafka.consumer.properties.request.timeout.ms=30000
spring.kafka.consumer.properties.default.api.timeout.ms=30000

# Circuit breaker configurations for Kafka
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.slidingWindowType=COUNT_BASED
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.slidingWindowSize=10
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.minimumNumberOfCalls=5
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.failureRateThreshold=50
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.waitDurationInOpenState=10000
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.permittedNumberOfCallsInHalfOpenState=3
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.automaticTransitionFromOpenToHalfOpenEnabled=true
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.slowCallRateThreshold=50
resilience4j.circuitbreaker.instances.kafkaCircuitBreaker.slowCallDurationThreshold=2000

spring.data.redis.host=host.docker.internal
spring.data.redis.port=6379


# # HashiCorp Vault
# spring.cloud.vault.token=another token
# spring.cloud.vault.scheme=http
# spring.cloud.vault.kv.enabled=true
# spring.config.import:  vault://

